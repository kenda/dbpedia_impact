"ITEMID", "TITLE", "TYPE", "confname", "DATE", "ISSN", "ISBN", "DOI", "URL", "PUB", "ISSUE", "VOLUME", "SERIES", "PAGES", "PUBLISHER", "PLACE", "PROCEEDINGS", "BOOK", "UNIVERSITY", "ARCHIVE_NAME", "ARCHIVE_LOCATION", "ABSTRACT", "AUTHOR_1_FIRST", "AUTHOR_1_LAST", "AUTHOR_1_SHORT", "AUTHOR_1_TYPE", "AUTHOR_2_FIRST", "AUTHOR_2_LAST", "AUTHOR_2_SHORT", "AUTHOR_2_TYPE", "AUTHOR_3_FIRST", "AUTHOR_3_LAST", "AUTHOR_3_SHORT", "AUTHOR_3_TYPE", "AUTHOR_4_FIRST", "AUTHOR_4_LAST", "AUTHOR_4_SHORT", "AUTHOR_4_TYPE", "AUTHOR_5_FIRST", "AUTHOR_5_LAST", "AUTHOR_5_SHORT", "AUTHOR_5_TYPE", "TAG_1", "TAG_2", "TAG_3", "TAG_4", "DATE_ADDED", "DATE_MODIFIED", "ZOTERO_KEY", "EXTRA"
"77", "Is there anything worth finding on the semantic web?", "conferencePaper", "WWW", "2009-00-00 2009", "", "978-1-60558-487-4", "10.1145/1526709.1526858", "http://doi.acm.org/10.1145/1526709.1526858", "", "", "", "WWW '09", "1065–1066", "ACM", "New York, NY, USA", "Proceedings of the 18th international conference on World wide web", "", "", "", "", "There has recently been an upsurge of interest in the possibilities of combining structured data and ad-hoc information retrieval from traditional hypertext. In this experiment, we run queries extracted from a query log of a major search engine against the Semantic Web to discover if the Semantic Web has anything of interest to the average user. We show that there is indeed much information on the Semantic Web that could be relevant for many queries for people, places and even abstract concepts, although they are overwhelmingly clustered around a Semantic Web-enabled export of Wikipedia known as DBPedia.", "Harry", "Halpin", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Linked Data", "information retrieval", "search", "semantic web", "2012-05-28 08:49:23", "2012-06-01 23:08:50", "6J9A3U6V", ""
"108", "Exploring the geospatial semantic web with dbpedia mobile", "journalArticle", "", "2009-00-00 2009", "", "", "", "", "J. Web Sem.", "4", "7", "", "278–286", "", "", "", "", "", "", "", "", "C.", "Becker", "", "author", "C.", "Bizer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:14:30", "2012-06-01 22:30:23", "XNNM7QXW", ""
"109", "DBpedia mobile: A location-enabled linked data browser", "conferencePaper", "LDOW", "2008-00-00 2008", "", "", "", "", "", "", "", "", "", "", "", "Linked Data on the Web (LDOW2008)", "", "", "", "", "In this demonstration, we present DBpedia Mobile, alocation-centric DBpedia client application for mobile devicesconsisting of a map view and a Fresnel-based LinkedData browser. The DBpedia project extracts structuredinformation from Wikipedia and publishes this informationas Linked Data on the Web. The DBpedia dataset containsinformation about 1.95 million things, including 200,000geographic locations. DBpedia is interlinked with variousother location-related datasets. Based on the current GPSposition of a mobile device, DBpedia Mobile renders amap indicating nearby locations from the DBpedia dataset.Starting from this map, users can explore background informationabout locations and can navigate into interlinkeddatasets. DBpedia Mobile demonstrates that the DBpediadataset can serve as a useful starting point to explore theGeospatial Semantic Web using a mobile device.", "C.", "Becker", "", "author", "C.", "Bizer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:14:30", "2012-06-01 22:00:15", "9FFM9JX9", ""
"113", "Preliminary results in tag disambiguation using dbpedia", "conferencePaper", "K-CAP", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "Knowledge Capture (K-Cap'09) - First International Workshop on Collective Knowledge Capturing and Representation", "", "", "", "", "", "A.", "Garcia", "", "author", "M.", "Szomszor", "", "author", "H.", "Alani", "", "author", "O.", "Corcho", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:14:30", "2012-06-01 23:29:21", "8K4DHH8C", ""
"126", "DBpedia mobile-a location-aware semantic web client", "conferencePaper", "ISWC", "2008-00-00 2008", "", "", "", "", "", "", "2008", "", "", "", "", "Proceedings of the Semantic Web Challenge at ISWC", "", "", "", "", "", "C.", "Becker", "", "author", "C.", "Bizer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:15:05", "2012-06-01 22:03:26", "MKH5F73G", ""
"128", "DBpedia—Querying Wikipedia like a database", "conferencePaper", "WWW", "2007-00-00 2007", "", "", "", "", "", "", "", "", "8–12", "", "", "Developers track presentation at the 16th international conference on World Wide Web, WWW", "", "", "", "", "", "C.", "Bizer", "", "author", "S.", "Auer", "", "author", "G.", "Kobilarov", "", "author", "J.", "Lehmann", "", "author", "R.", "Cyganiak", "", "author", "", "", "", "", "2012-05-23 20:15:05", "2012-06-01 22:07:54", "P26BXMJK", ""
"131", "Semantic wonder cloud: exploratory search in dbpedia", "conferencePaper", "ICWE", "2010-00-00 2010", "", "", "", "", "", "", "", "", "138–149", "", "", "Current Trends in Web Engineering", "", "", "", "", "", "R.", "Mirizzi", "", "author", "A.", "Ragone", "", "author", "T.", "Di Noia", "", "author", "E.", "Di Sciascio", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:15:05", "2012-06-01 23:50:04", "EFUAS4WE", ""
"132", "The Semantic Gap of Formalized Meaning", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "http://data.semanticweb.org/conference/eswc/2010/paper/phd_symposium/30", "", "", "", "", "", "", "", "7th Extended Semantic Web Conference (ESWC2010)", "", "", "", "", "Recent work in Ontology Learning and Textmining mainly focused on engineering methods to solve practical problem. In this thesis, we investigate methods that can substantially improve a wide range of existing approaches by minimizing the underlying problem: The Semantic Gap between formalized meaning and human cognition. We deploy OWL as a Meaning Representation Language and create a unified model, which combines existing NLP methods with Linguistic knowledge and aggregates disambiguated background knowledge from the Web of Data. The presented methodology allows to study and evaluate the capabilities of such aggregated knowledge to improve the efficiency of methods in Ontology Learning.", "", "Sebastian Hellmann", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:55:31", "BIIJFAMQ", ""
"135", "DBpedia spotlight: shedding light on the web of documents", "conferencePaper", "I-SEMANTICS", "2011-00-00 2011", "", "", "", "", "", "", "", "", "1–8", "", "", "Proceedings of the 7th International Conference on Semantic Systems", "", "", "", "", "", "P. N", "Mendes", "", "author", "M.", "Jakob", "", "author", "A.", "García-Silva", "", "author", "C.", "Bizer", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:15:05", "2012-06-01 22:09:31", "KAPRA3FB", ""
"139", "DBpedia–A Linked Data Hub and Data Source for Web Applications and Enterprises", "conferencePaper", "WWW", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "In Proceedings of Developers Track of 18th International World Wide Web Conference", "", "", "", "", "", "G.", "Kobilarov", "", "author", "C.", "Bizer", "", "author", "S.", "Auer", "", "author", "J.", "Lehmann", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:15:05", "2012-06-01 21:26:33", "4WQAR8A4", ""
"140", "Semantic tag cloud generation via DBpedia", "conferencePaper", "ECWeb", "2010-00-00 2010", "", "", "", "", "", "", "", "", "36–48", "", "", "11th International Conference on Electronic Commerce and Web Technologies ECWeb10 (2010)", "", "", "", "", "Many current recommender systems exploit textual annotations (tags) provided by users to retrieve and suggest online contents. The text-based recommendation provided by these systems could be enhanced (i) using unambiguous identifiers representative of tags and (ii) exploiting semantic relations among tags which are impossible to be discovered by traditional textual analysis. In this paper we concentrate on annotation and retrieval of web content, exploiting semantic tagging with DBpedia. We use semantic information stored in the DBpedia dataset and propose a new hybrid ranking system to rank keywords and to expand queries for- mulated by the user. Inputs of our ranking system are (i) the DBpedia dataset; (ii) external information sources such as classical search engine results and social tagging systems. We compare our approach with other RDF similarity measures, proving the validity of our algorithm with an extensive evaluation involving real users.", "R.", "Mirizzi", "", "author", "A.", "Ragone", "", "author", "T.", "Di Noia", "", "author", "E.", "Di Sciascio", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:15:05", "2012-06-01 23:43:18", "DGNMUJVF", ""
"149", "Towards linked data internationalization-realizing the Greek DBpedia", "conferencePaper", "ACM WebSci", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the ACM WebSci'11", "", "", "", "", "", "D.", "Kontokostas", "", "author", "C.", "Bratsas", "", "author", "S.", "Auer", "", "author", "S.", "Hellmann", "", "author", "I.", "Antoniou", "", "author", "", "", "", "", "2012-05-23 20:15:48", "2012-06-02 00:01:53", "8334RRAR", ""
"151", "Update Strategies for DBpedia Live", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "6th Workshop on Scripting and Development for the Semantic Web Colocated with ESWC", "", "", "", "", "", "C.", "Stadler", "", "author", "M.", "Martin", "", "author", "J.", "Lehmann", "", "author", "S.", "Hellmann", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:15:48", "2012-06-02 00:04:42", "KKGDV7S3", ""
"153", "DBpedia Navigator", "conferencePaper", "ISWC", "2008-00-00 2008", "", "", "", "", "", "", "", "", "", "", "", "ISWC Billion Triple Challenge", "", "", "", "", "", "J.", "Lehmann", "", "author", "S.", "Knappe", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:15:48", "2012-06-01 22:05:55", "UN5UXFXU", ""
"157", "Movie recommendation with dbpedia", "conferencePaper", "IIR", "2012-00-00 2012", "", "", "", "", "", "", "", "", "", "", "", "3rd Italian Information Retrieval Workshop (IIR 2012). CEUR-WS", "", "", "", "", "", "R.", "Mirizzi", "", "author", "T.", "Di Noia", "", "author", "A.", "Ragone", "", "author", "V.", "Ostuni", "", "author", "E.", "Di Sciascio", "", "author", "", "", "", "", "2012-05-23 20:15:48", "2012-06-01 23:23:20", "62B386PS", ""
"158", "DSNotify: handling broken links in the web of data", "conferencePaper", "WWW", "2010-00-00 2010", "", "978-1-60558-799-8", "10.1145/1772690.1772768", "http://doi.acm.org/10.1145/1772690.1772768", "", "", "", "WWW '10", "761–770", "ACM", "New York, NY, USA", "Proceedings of the 19th international conference on World wide web", "", "", "", "", "The Web of Data has emerged as a way of exposing structured linked data on the Web. It builds on the central building blocks of the Web (URIs, HTTP) and benefits from its simplicity and wide-spread adoption. It does, however, also inherit the unresolved issues such as the broken link problem. Broken links constitute a major challenge for actors consuming Linked Data as they require them to deal with reduced accessibility of data. We believe that the broken link problem is a major threat to the whole Web of Data idea and that both Linked Data consumers and providers will require solutions that deal with this problem. Since no general solutions for fixing such links in the Web of Data have emerged, we make three contributions into this direction: first, we provide a concise definition of the broken link problem and a comprehensive analysis of existing approaches. Second, we present DSNotify, a generic framework able to assist human and machine actors in fixing broken links. It uses heuristic feature comparison and employs a time-interval-based blocking technique for the underlying instance matching problem. Third, we derived benchmark datasets from knowledge bases such as DBpedia and evaluated the effectiveness of our approach with respect to the broken link problem. Our results show the feasibility of a time-interval-based blocking approach for systems that aim at detecting and fixing broken links in the Web of Data.", "Niko P.", "Popitsch", "", "author", "Bernhard", "Haslhofer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "Linked Data", "blocking", "broken links", "instance matching", "2012-05-28 08:49:30", "2012-06-01 22:19:51", "29UEW6TD", ""
"160", "Bridging Ontologies and Folksonomies using DBpedia", "conferencePaper", "CSCS", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "the proceedings of the 17th International Conference on Control Systems and Computer Science. Bucharest, Romania", "", "", "", "", "", "V.", "Posea", "", "author", "S.", "Trausan-Matu", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:15:48", "2012-06-01 21:13:12", "BWKXS9SS", ""
"162", "DBpedia–Extracting structured data from Wikipedia", "conferencePaper", "Wikimania", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "Presentation à Wikimania, Buenos Aires, Argentine", "", "", "", "", "The DBpedia project is a community effort to extract structured information from Wikipedia and to make this information accessible on the Web as Linked Data. DBpedia allows one to ask sophisticated queries against Wikipedia, and to link other open data sets on the Web to Wikipedia data. Currently, the Web of interlinked data sources around DBpedia provides over 4.5 billion pieces of information and covers domains such as geographic information, people, companies, films, music, genes, drugs, books, and scientific publications.", "C.", "Becker", "", "author", "A.", "Jentzsch", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:15:48", "2012-06-01 21:38:30", "2XTZCBFX", ""
"169", "FRBRPedia: a tool for FRBRizing web products and linking FRBR entities to DBpedia", "conferencePaper", "JCDL", "2011-00-00 2011", "", "", "", "", "", "", "", "", "455–456", "", "", "Proceeding of the 11th annual international ACM/IEEE joint conference on Digital libraries", "", "", "", "", "", "F.", "Duchateau", "", "author", "N.", "Takhirov", "", "author", "T.", "Aalberg", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:12", "2012-06-01 22:32:40", "2EQ8B8TK", ""
"171", "Evaluating DBpedia Spotlight for the TAC-KBP Entity Linking Task", "conferencePaper", "TAC", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the TACKBP 2011 Workshop", "", "", "", "", "", "P. N", "Mendes", "", "author", "J.", "Daiber", "", "author", "M.", "Jakob", "", "author", "C.", "Bizer", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:19:12", "2012-06-01 22:27:27", "VHN5IAQ5", ""
"173", "WhoKnows? Evaluating linked data heuristics with a quiz that cleans up DBpedia", "journalArticle", "", "2011-00-00 2011", "", "", "", "", "Interactive Technology and Smart Education", "4", "8", "", "236–248", "", "", "", "", "", "", "", "", "J.", "Waitelonis", "", "author", "N.", "Ludwig", "", "author", "M.", "Knuth", "", "author", "H.", "Sack", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:19:12", "2012-05-23 20:19:12", "6T6BS7TS", ""
"175", "Gorelations: An intuitive query system for dbpedia", "conferencePaper", "JIST", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the Joint International Semantic Technology Conference", "", "", "", "", "Although a formal query language, SPARQL, is available for accessing DBpedia, it remains challenging for users to query the knowledge unless they are familiar with the syntax of SPARQL and the underlying ontology. We have developed both an intuitive semantic graph notation or interface allowing one to pose a query by annotating a graph with natural language terms denoting entities and relations and a system that automatically translates the query into SPARQL to produce an answer. Our key contributions are the robust techniques, combining statistical association and semantic similarity, that map user terms to the most appropriate classes and properties used in the DBpedia Ontology.", "L.", "Han", "", "author", "T.", "Finin", "", "author", "A.", "Joshi", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:12", "2012-06-01 22:40:40", "7QEAGFW9", ""
"182", "Building “Bag of Conception” Model Based on DBpedia", "journalArticle", "", "2009-00-00 2009", "", "", "", "", "Advances in Software Engineering", "", "", "", "66–78", "", "", "", "", "", "", "", "", "J.", "Liao", "", "author", "R.", "Bai", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:40", "2012-05-23 20:19:40", "TTTNNDPD", ""
"183", "INEX+ DBPEDIA: a corpus for semantic search evaluation", "conferencePaper", "WWW", "2010-00-00 2010", "", "", "", "", "", "", "", "", "1161–1162", "", "", "Proceedings of the 19th international conference on World wide web", "", "", "", "", "", "J. R", "Perez-Aguera", "", "author", "J.", "Arroyo", "", "author", "J.", "Greenberg", "", "author", "J.", "Perez-Iglesias", "", "author", "V.", "Fresno", "", "author", "", "", "", "", "2012-05-23 20:19:40", "2012-06-01 22:49:07", "VJBB3SHP", ""
"188", "Meta search engine powered by DBpedia", "conferencePaper", "STAIR", "2011-00-00 2011", "", "", "", "", "", "", "", "", "89–93", "", "", "Semantic Technology and Information Retrieval (STAIR), 2011 International Conference on", "", "", "", "", "", "B. V", "Keong", "", "author", "P.", "Anthony", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:40", "2012-06-01 23:21:16", "G7TJS3SU", ""
"190", "The German DBpedia: A Sense Repository for Linking Entities", "conferencePaper", "LDL", "2012-00-00 2012", "", "", "", "", "", "", "", "", "181–190", "", "", "Linked Data in Linguistics", "", "", "", "", "", "S.", "Hellmann", "", "author", "C.", "Stadler", "", "author", "J.", "Lehmann", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:40", "2012-06-01 23:53:16", "64S4F5KI", ""
"194", "A framework for integrating DBpedia in a multi-modality ontology news image retrieval system", "conferencePaper", "STAIR", "2011-00-00 2011", "", "", "", "", "", "", "", "", "144–149", "", "", "Semantic Technology and Information Retrieval (STAIR), 2011 International Conference on", "", "", "", "", "", "Y. I.", "Khalid", "", "author", "S. A.", "Noah", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:40", "2012-06-01 20:54:38", "9CTETX3K", ""
"195", "Models for Efficient Semantic Data Storage Demonstrated on Concrete Example of DBpedia", "conferencePaper", "DATESO", "2012-00-00 2012", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "I.", "Lašek", "", "author", "P.", "Vojtáš", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:40", "2012-06-01 23:23:10", "U3MJJ42N", ""
"201", "Integrating DBpedia in multi-modality ontology news image retrieval", "conferencePaper", "ICT4M", "2010-00-00 2010", "", "", "", "", "", "", "", "", "E4–E8", "", "", "Information and Communication Technology for the Muslim World (ICT4M), 2010 International Conference on", "", "", "", "", "", "M. K.", "Yanti Idaya Aspura", "", "author", "S.", "Azman", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 22:51:49", "NTKTW29F", ""
"202", "Semantic Linking of a Learning Object Repository to DBpedia", "conferencePaper", "ICALT", "2011-00-00 2011", "", "", "", "", "", "", "", "", "460–464", "", "", "Advanced Learning Technologies (ICALT), 2011 11th IEEE International Conference on", "", "", "", "", "", "M.", "Lama", "", "author", "J. C", "Vidal", "", "author", "E. O", "Garcia", "", "author", "A.", "Bugarín", "", "author", "S.", "Barro", "", "author", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 23:41:34", "QJFWW85K", ""
"203", "Internationalization of Linked Data: The case of the Greek DBpedia edition", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "J. Web Sem.", "", "", "", "", "", "", "", "", "", "", "", "", "D.", "Kontokostas", "", "author", "C.", "Bratsas", "", "author", "S.", "Auer", "", "author", "S.", "Hellmann", "", "author", "I.", "Antoniou", "", "author", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 23:08:38", "KRDVB5DH", ""
"205", "Semantic Clustering of Scientific Articles with Use of DBpedia Knowledge Base", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "Intelligent Tools for Building a Scientific Information Platform", "", "", "", "61–76", "", "", "", "", "", "", "", "A case study of semantic clustering of scientific articles related to Rough Sets is presented. The proposed method groups the documents on the basis of their content and with assistance of DBpedia knowledge base. The text corpus is first treated with Natural Language Processing tools in order to produce vector representations of the content and then matched against a collection of concepts retrieved from DBpedia. As a result, a new representation is constructed that better reflects the semantics of the texts. With this new representation, the documents are hierarchically clustered in order to form partition of papers that share semantic relatedness. The steps in textual data preparation, utilization of DBpedia and clustering are explained and illustrated with experimental results. Assessment of clustering quality by human experts and by comparison to traditional approach is presented.", "M.", "Szczuka", "", "author", "A.", "Janusz", "", "author", "K.", "Herba", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 23:40:54", "S2QUT5TV", ""
"206", "Integrating DBpedia and SentiWordNet for a tourism recommender system", "conferencePaper", "ICCP", "2011-00-00 2011", "", "", "", "", "", "", "", "", "133–136", "", "", "Intelligent Computer Communication and Processing (ICCP), 2011 IEEE International Conference on", "", "", "", "", "", "B.", "Varga", "", "author", "A.", "Groza", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 22:51:14", "B22B6FNN", ""
"207", "Discovering Relevant Topics Using DBPedia: Providing Non-obvious Recommendations", "conferencePaper", "WI-IAT", "2011-00-00 2011", "", "", "", "", "", "", "1", "", "219–222", "", "", "Web Intelligence and Intelligent Agent Technology (WI-IAT), 2011 IEEE/WIC/ACM International Conference on", "", "", "", "", "", "M.", "Stankovic", "", "author", "W.", "Breitfuss", "", "author", "P.", "Laublet", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 22:15:11", "IEQK3R6Z", ""
"209", "Identifying Topics in Social Media Posts using DBpedia", "conferencePaper", "NEM", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "In Proceedings of the NEM Summit", "", "", "", "", "This paper describes a method for identifying topics in text published in social media, by applying topic recognition techniques that exploit DBpedia. We evaluate such method for social media in Spanish and we provide the results of the evaluation performed.", "O.", "Muñoz-García", "", "author", "A.", "García-Silva", "", "author", "Ó", "Corcho", "", "author", "M.", "de la Higuera Hernández", "", "author", "C.", "Navarro", "", "author", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 22:44:13", "8XJR4CX2", ""
"211", "An Approach for Supplementing the Korean Wikipedia based on DBpedia", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "E.", "Kim", "", "author", "D. H", "Choi", "", "author", "J.", "Lee", "", "author", "J. H", "Ahn", "", "author", "K. S", "Choi", "", "author", "", "", "", "", "2012-05-23 20:19:59", "2012-06-21 17:55:27", "BAW2EJVM", ""
"213", "Semantic Web Game Based Learning: An I18n approach with Greek DBpedia", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "", "C.", "Bratsas", "", "author", "D. E", "Chrysou", "", "author", "A.", "Eftychiadou", "", "author", "D.", "Kontokostas", "", "author", "P.", "Bamidis", "", "author", "", "", "", "", "2012-05-23 20:19:59", "2012-06-01 23:47:31", "NT6ZF9PZ", ""
"222", "Improving Wikipedia with DBpedia", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "", "", "", "", "", "1107–1112", "", "", "Proceedings of the 21st international conference companion on World Wide Web", "", "", "", "", "DBpedia is the semantic mirror of Wikipedia. DBpedia extracts information from Wikipedia and stores it in a semantic knowledge base. This semantic feature relies in making complex queries inferring relations among articles which sometimes are missing in Wikipedia. This difference generates an information gap between DBpedia and Wikipedia. Could be improved Wikipedia with DBpedia new information to reduce this gap? How this new information should be added to Wikipedia? In this article, we propose a path indexing algorithm (PIA) who takes a data set of a DBPedia query and returns the best representative path to be applied in the Wikipedia. We evaluate the results of applying PIA to express the relation between people and their birth city.", "D.", "Torres", "", "author", "P.", "Molli", "", "author", "H.", "Skaf-Molli", "", "author", "A.", "Diaz", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:20:20", "2012-06-01 22:47:09", "59W8DSAT", ""
"226", "Slicing linked data by extracting significant, self-describing subsets: the DBpedia case", "conferencePaper", "ICWE", "2010-00-00 2010", "", "", "", "", "", "", "", "", "223–231", "", "", "Current Trends in Web Engineering", "", "", "", "", "", "M.", "Minno", "", "author", "D.", "Palmisano", "", "author", "M.", "Mostarda", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:20", "2012-06-01 23:50:44", "ISMDJKSG", ""
"230", "Domain-aware Matching of Events to DBpedia", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "", "", "", "779", "", "117–121", "", "", "Proceedings of the Workhop on Detection, Representation, and Exploitation of Events in the Semantic Web (DeRiVE 2011), workshop in conjunction with the 10th International Semantic Web Conference 2011 (ISWC 2011)$}$", "", "", "", "", "", "K.", "Slabbekoorn", "", "author", "L.", "Hollink", "", "author", "G. J", "Houben", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:20", "2012-06-01 22:17:44", "WCBPKHUX", ""
"236", "Round-trip semantics with Sztakipedia and DBpedia Spotlight", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "", "", "", "", "", "357–360", "", "", "Proceedings of the 21st international conference companion on World Wide Web", "", "", "", "", "We describe a tool kit to support a knowledge-enhancement cycle on the Web. In the first step, structured data which is extracted from Wikipedia is used to construct automatic content enhancement engines. Those engines can be used to interconnect knowledge in structured and unstructured information sources on the Web, including Wikipedia it- self. Sztakipedia-toolbar is a MediaWiki user script which brings DBpedia Spotlight and other kinds of machine in- telligence into the Wiki editor interface to provide enhance- ment suggestions to the user. The suggestions offered by the tool focus on complementing knowledge and increasing the availability of structured data on Wikipedia. This will, in turn, increase the available information for the content en- hancement engines themselves, completing a virtuous cycle of knowledge enhancement.", "M.", "Héder", "", "author", "P. N", "Mendes", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:20", "2012-06-01 23:39:20", "9GZCKVND", ""
"239", "DBpedia: A Multilingual Cross-Domain Knowledge Base", "conferencePaper", "LREC", "2012-00-00 2012", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the International Conference on Language Resources and Evaluation", "", "", "", "", "", "P. N", "Mendes", "", "author", "M.", "Jakob", "", "author", "C.", "Bizer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:20", "2012-06-01 21:29:22", "UUIFEQXF", ""
"247", "Integrating Knowledge of City Entities Extracted from DBpedia and GeoLite into the EKOSS Failure Cases Repository to Enhance Semantic Search Capabilities", "journalArticle", "", "2011-00-00 2011", "", "", "", "", "ijcisim", "", "", "", "", "", "", "", "", "", "", "", "", "W.", "Guo", "", "author", "S. B", "Kraines", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:37", "2012-06-01 23:05:04", "ZDCSWUC2", ""
"249", "DBpedia and the Live Extraction of Structured Data from Wikipedia", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "Program: electronic library and information systems", "2", "46", "", "2–2", "", "", "", "", "", "", "", "", "M.", "Morsey", "", "author", "J.", "Lehmann", "", "author", "S.", "Auer", "", "author", "C.", "Stadler", "", "author", "S.", "Hellmann", "", "author", "", "", "", "", "2012-05-23 20:20:37", "2012-05-23 20:20:37", "RMTFGQGT", ""
"250", "Towards Better Understanding and Utilizing Relations in DBpedia", "journalArticle", "", "", "", "", "", "", "Web Intelligence and Agent Systems", "", "", "", "", "", "", "", "", "", "", "", "", "L.", "Fu", "", "author", "H.", "Wang", "", "author", "Y.", "Yu", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:37", "2012-06-01 23:58:39", "7AHEHC28", ""
"251", "Google Knows Who is Famous Today–Building an Ontology from Search Engine Knowledge and DBpedia", "conferencePaper", "ICSC", "2011-00-00 2011", "", "", "", "", "", "", "", "", "320–327", "", "", "Semantic Computing (ICSC), 2011 Fifth IEEE International Conference on", "", "", "", "", "", "C.", "Ochs", "", "author", "T.", "Tian", "", "author", "J.", "Geller", "", "author", "S.", "Chun", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:20:37", "2012-06-01 22:37:44", "I5JPWHKQ", ""
"252", "Generating Educational Assessment Items from Linked Open Data: The Case of DBpedia", "conferencePaper", "ESWC", "2011-00-00 2011", "", "", "", "", "", "", "", "", "16–27", "", "", "The Semantic Web: ESWC 2011 Workshops", "", "", "", "", "", "M.", "Foulonneau", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:37", "2012-06-01 22:37:16", "97MRGVK3", ""
"253", "Towards a Korean DBpedia and an Approach for Complementing the Korean Wikipedia based on DBpedia", "conferencePaper", "OKCon", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the 5th Open Knowledge Conference", "", "", "", "", "", "E.", "Kim", "", "author", "M.", "Weidl", "", "author", "K. S", "Choi", "", "author", "S.", "Auer", "", "author", "", "", "", "", "", "", "", "", "2012-05-23 20:20:37", "2012-06-01 23:57:04", "EJXQ4EU8", ""
"261", "Web data fusion in the Wikipedia/DBpedia domain", "conferencePaper", "IFIP", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "E.", "TACCHINI", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-23 20:20:54", "2012-06-21 18:14:57", "A6R8T74R", ""
"282", "Type inference through the analysis of Wikipedia links", "conferencePaper", "LDOW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/workshop/ldow/2012/paper/30", "", "", "", "", "", "", "", "LDOW 2012 : linked Data on the web (LDOW2012)", "", "", "", "", "DBpedia contains millions of untyped entities, either if we consider the native DBpedia ontology, or Yago plus WordNet. Is it possible to automatically classify those entities? Based on previous work on wikilink invariances, we wondered if wikilinks convey a knowledge rich enough for their classification.In this paper we give three contributions. Concerning the DBpedia link structure, we describe some measurements and notice both problems (e.g. the bias that could be induced by the incomplete ontological coverage of the DBpedia ontology), and potentials existing in current type coverage. Concerning classification, we present two techniques that exploit wikilinks, one based on induction from machine learning techniques, and the other on abduction. Finally, we discuss the limited results of classification, which confirmed our fears expressed in the description of general figures from the measurement. We also suggest some new possible approaches to entity classification that could be taken, based on more solid grounds.", "Andrea", "Nuzzolese", "", "author", "Aldo", "Gangemi", "", "author", "Valentina", "Presutti", "", "author", "Paolo", "Ciancarini", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-02 00:02:00", "RXZTG7QR", ""
"285", ":me owl:sameAs flickr:33669349@N00 .", "conferencePaper", "LDOW", "2008-00-00 2008", "", "", "", "http://data.semanticweb.org/workshop/LDOW/2008/paper/16", "", "", "", "", "", "", "", "Linked Data on the Web (LDOW2008)", "", "", "", "", "In order to release the Social Semantic Web and solve data-portability issues, there is a need from Web 2.0 providers to open their data and deliver it in machine-redeable way. Modeling it with vocabularies as FOAF, SIOC, as well as reusing data from the Linked Data initiative as DBpedia or geonames.org can help to achieve this task.The goal of this demo is to showcase a RDF exporter for Flickr profiles that acts such a way.", "", "Alexandre Passant", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-21 18:30:15", "APPCBBGZ", ""
"286", "URI Disambiguation in the Context of Linked Data", "conferencePaper", "LDOW", "2008-00-00 2008", "", "", "", "http://data.semanticweb.org/workshop/LDOW/2008/paper/5", "", "", "", "", "", "", "", "Linked Data on the Web (LDOW2008)", "", "", "", "", "The Linked Data initiative has given rise to an increasing number of RDF datasets, many of which are freely accessible online. These resources often arise as a result of database exports; however sufficient consideration may not be given to the unseen implications caused when they are used in the wider context of the Semantic Web. This paper investigates two popular resources, DBLP and DBpedia, and discusses whether the issues regarding identity management and co-reference resolution have been suitably addressed. We find that a large percentage of authors in DBLP have been conflated, and that disambiguation pages have been incorrectly linked using owl:sameAs within DBpedia. Systems for dealing with these issues are presented, and directions are given for future research.", "", "Afraz Jaffri", "", "author", "", "Hugh Glaser", "", "author", "", "Ian Millard", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-02 00:05:41", "JHTM6INB", ""
"288", "XSLT+SPARQL: Scripting the Semantic Web with SPARQL embedded into XSLT stylesheets", "conferencePaper", "SFSW", "2008-00-00 2008", "", "", "", "http://data.semanticweb.org/workshop/scripting/2008/paper/1", "", "", "", "", "", "", "", "4th Workshop on Scripting for the Semantic Web (SFSW2008)", "", "", "", "", "Scripting the Semantic Web requires to access and transform RDF data. We present XSLT+SPARQL, a set of extension functions for XSLT which allow stylesheets to directly access RDF data, independently of any serialization syntax, by means of SPARQL queries. Using these functions, XSLT stylesheets can retrieve, query, merge and transform data from the semantic web. We illustrate the functionality of our proposal with an example script which creates XHTML pages from the contents of DBpedia.", "", "Diego Berrueta", "", "author", "", "Jose E. Labra", "", "author", "", "Ivan Herman", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-02 00:11:52", "FV9BFTTZ", ""
"289", "Learning of OWL Class Descriptions on Very Large Knowledge Bases", "conferencePaper", "ISWC", "2008-00-00 2008", "", "", "", "http://data.semanticweb.org/conference/iswc/2008/paper/poster_demo/83", "", "", "", "", "", "", "", "7th International Semantic Web Conference (ISWC2008)", "", "", "", "", "The vision of the Semantic Web is to make use of semantic representations on the largest possible scale - the Web. Large knowledge bases such as DBpedia, OpenCyc, GovTrack, and others are emerging and are freely available as Linked Data and SPARQL endpoints. Exploring and analysing such knowledge bases is a significant hurdle for Semantic Web research and practice. As one possible direction for tackling this problem, we present an approach for obtaining complex class descriptions from objects in knowledge bases by using Machine Learning techniques. We describe how we leverage existing techniques to achieve scalability on large knowledge bases available as SPARQL endpoints or Linked Data. Our algorithms are made available in the open source DL-Learner project and can be used in real-life scenarios by Semantic Web applications.", "", "Sebastian Hellmann", "", "author", "", "Jens Lehmann", "", "author", "", "Sören Auer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:10:30", "KAWT29A4", ""
"295", "Interactive Relationship Discovery via the Semantic Web", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "http://data.semanticweb.org/conference/eswc/2010/paper/inuse/31", "", "", "", "", "", "", "", "7th Extended Semantic Web Conference (ESWC2010)", "", "", "", "", "This paper presents an approach for the interactive discovery of relationships between selected elements via the Semantic Web. It fills the gap between algorithms that find relationships in datasets of the Semantic Web and their efficient usage in real-world contexts. Selected elements are first semi-automatically mapped to unique objects of Semantic Web datasets. These datasets are then crawled for relationships which are presented both, in detail and overview. Interactive features and visual clues allow for sophisticated exploration of the found relationships on different levels. The general process is described and the RelFinder tool as a concrete implementation and proof-of-concept is presented. The benefits and application potentials are illustrated by a scenario which uses the RelFinder and DBpedia to assist a business analyst in decision-making. Finally, the approach is evaluated in a user study, and discussed and compared with related work.", "", "Philipp Heim", "", "author", "", "Steen Lohmann", "", "author", "", "Timo Stegemann", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:08:08", "6ES5K2ZB", ""
"296", "Replication and Versioning of Partial RDF Graphs", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "http://data.semanticweb.org/conference/eswc/2010/paper/mobility/6", "", "", "", "", "", "", "", "7th Extended Semantic Web Conference (ESWC2010)", "", "", "", "", "The sizes of datasets available as RDF (e.g., as part of the Linked Data cloud) are increasing continuously. For instance, the recent DBpedia version consists of nearly 500 millions triples. A common strategy to avoid problems that arise e.g., from limited network connectivity or lack of bandwidth is to replicate data locally, therefore making them accessible for applications without depending on a network connection. For mobile devices with limited capabilities, however, the replication and synchronization of billions of triples is not feasible. To overcome this problem, we propose an approach to replicate parts of an RDF graph to a client. Applications may then apply changes to this partial replica while being offline; these changes are written back to the original data source upon reconnection. Our approach does not require any kind of additional logic (e.g., change logging) or data structures on the client side, and hence is suitable to be applied on devices with limited computing power and storage capacity.", "", "Bernhard Schandl", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:37:57", "75XMDSVI", ""
"297", "Using social media for ontology enrichment", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "http://data.semanticweb.org/conference/eswc/2010/paper/social_web/29", "", "", "", "", "", "", "", "7th Extended Semantic Web Conference (ESWC2010)", "", "", "", "", "In order to support informal learning, we complement the formal knowledge represented by ontologies developed by domain experts with the informal knowledge emerging from social tagging. To this end, we have developed an ontology enrichment pipeline that can automatically enrich a domain ontology using: data extracted by a crawler from social media applications, similarity measures, the DBpedia knowledge base, a disambiguation algorithm and several heuristics. The main goal is to provide dynamic and personalized domain ontologies that include the knowledge of the community of users. They will support a more personalized learning experience able to fulfill the needs of different types of learners.", "", "Paola Monachesi", "", "author", "", "Thomas Markus", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-02 00:08:10", "FNP9CVG8", ""
"298", "The Impact of Multifaceted Tagging on Learning Tag Relations and Search", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "http://data.semanticweb.org/conference/eswc/2010/paper/social_web/4", "", "", "", "", "", "", "", "7th Extended Semantic Web Conference (ESWC2010)", "", "", "", "", "In this paper we present a model for multifaceted tagging, i.e. tagging enriched with contextual information. We present TagMe!, a social tagging front-end for Flickr images, that provides multifaceted tagging functionality: It enables users to attach tag assignments to a specific area within an image and to categorize tag assignments. Moreover, TagMe! automatically maps tags and categories to DBpedia URIs to clearly define the meaning of freely-chosen words. Our experiments reveal the benefits of those additional tagging facets. For example, the exploitation of those facets significantly improves the performance of FolkRank-based search. Further, we demonstrate the benefits of TagMe! tagging facets for learning semantics within folksonomies.", "", "Fabian Abel", "", "author", "", "Nicola Henze", "", "author", "", "Ricardo Kawase", "", "author", "", "Daniel Krause", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:54:03", "UNAK9UW2", ""
"299", "Object Link Structure in the Semantic Web", "conferencePaper", "ESWC", "2010-00-00 2010", "", "", "", "http://data.semanticweb.org/conference/eswc/2010/paper/web_of_data/8", "", "", "", "", "", "", "", "7th Extended Semantic Web Conference (ESWC2010)", "", "", "", "", "Lots of RDF data have been published in the Semantic Web. The RDF data model, together with the decentralized linkage nature of the Semantic Web, brings object link structure to the worldwide scope. Object links are critical to the Semantic Web and the macroscopic properties of object links are helpful for better understanding the current Data Web. In this paper, we propose a notion of object link graph (OLG) in the Semantic Web, and analyze the complex network structure of an OLG constructed from the latest dataset (FC09) collected by Falcons. We find that the OLG has the scale-free nature and the effective diameter of the graph is small compared to its scale. By another experimental result on the last year”s dataset (FC08), we confirm our findings and observe that the object link graph is becoming denser and its diameter is shrinking during the past year, which indicates a good evolution of the Data Web. Finally, we repeat the complex network analysis on the two largest domain-specific subsets of FC09, namely Bio2RDF(FC09) and DBpedia(FC09). The results show that both Bio2RDF(FC09) and DBpedia(FC09) have low density in object links, which has great influence on the density of object links in FC09.", "", "Weiyi Ge", "", "author", "", "Jianfeng Chen", "", "author", "", "Wei Hu", "", "author", "", "Yuzhong Qu", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:27:54", "8WP5PM96", ""
"300", "CoSi: Context-Sensitive Keyword Query Interpretation on RDF Databases", "conferencePaper", "WWW", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/www/2011/demo/cosi-context-sensitive-keyword-query-interpretatio", "", "", "", "", "209", "", "", "20th International World Wide Web Conference (WWW2011)", "", "", "", "", "The demo will present CoSi, a system that enables context-sensitive interpretation of keyword queries on RDF databases. The techniques for representing, managing and exploiting query history are central to achieving this objective. The demonstration will show the effectiveness of our approach for capturing a user's querying context from their query history. Further, it will show how context is utilized to influence the interpretation of a new query. The demonstration is based on DBPedia, the RDF representation of Wikipedia.", "Haizhou", "Fu", "", "author", "Sidan", "Gao", "", "author", "Kemafor", "Anyanwu", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:22:20", "ENE7CTGT", ""
"302", "AutoSPARQL: Let Users Query Your Knowledge Base", "conferencePaper", "ESWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/eswc/2011/paper/inductive-approaches/6", "", "", "", "", "", "", "", "8th Extended Semantic Web Conference (ESWC2011)", "", "", "", "", "An advantage of Semantic Web standards like RDF and OWL is their flexibility in modifying the structure of a knowledge base. To turn this flexibility into a practical advantage, it is of high importance to have tools and methods, which offer similar flexibility in extracting information from a knowledge base. This is closely related to the ability to easily formulate queries over those knowledge bases. We explain benefits and drawbacks of existing techniques in achieving this goal and then present the QTL algorithm, which fills a gap in research and practice. It uses supervised machine learning and allows users to ask queries without knowing the schema of the underlying knowledge base beforehand and without expertise in the SPARQL query language. We then present the AutoSPARQL user interface, which implements an active learning approach on top of QTL. Finally, we present an evaluation based on the SPARQL query log of the DBpedia knowledge base.", "Jens", "Lehmann", "", "author", "Lorenz", "Bühmann", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:10:26", "BTTNT7J5", ""
"303", "Statistical Schema Induction", "conferencePaper", "ESWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/eswc/2011/paper/linked-open-data/8", "", "", "", "", "", "", "", "8th Extended Semantic Web Conference (ESWC2011)", "", "", "", "", "While the realization of the Semantic Web as once envisioned by Tim Berners-Lee remains in a distant future, the Web of Data has already become a reality. Billions of RDF statements out there on the Internet, facts about a variety of different domains, are ready to be used by semantic applications. Some of these applications, however, crucially hinge on the availability of expressive schemas suitable for logical inference that yields non-trivial conclusions. In this paper, we present a statistical approach to the induction of expressive schemas from large RDF repositories. We describe in detail the implementation of this approach and report on an evaluation that we conducted using several data sets including DBpedia.", "Johanna", "Voelker", "", "author", "Mathias", "Niepert", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:51:59", "UBMT5D3F", ""
"304", "Lightweight Semantic Annotation of Geospatial RESTful Services", "conferencePaper", "ESWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/eswc/2011/paper/services/5", "", "", "", "", "", "", "", "()", "", "", "", "", "RESTful services are increasingly gaining traction over WS-* ones. As with WS-* services, their semantic annotation can provide benefits in tasks related to their discovery, composition and mediation. In this paper we present an approach to automate the semantic annotation of RESTful services using a cross-domain ontology, two semantic resources like DBpedia and GeoNames, and additional external resources (suggestion and synonym services). We also present a preliminary evaluation in the geospatial domain that proves the feasibility of our approach in a domain where RESTful services are increasingly appearing and highlights that it is possible to carry out this semantic annotation with satisfactory results.", "", "Victor Saquicela", "", "author", "", "Luis M. Vilches-Blazquez", "", "author", "", "Oscar Corcho", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 20:44:09", "32BM3KW8", ""
"305", "DC Proposal: Ontology Learning from Noisy Linked Data", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/doctoral-consortium/20", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "Mobile devices like smartphones together with social networks enable people to generate, share, and consume enormous amounts of media content. Common search operations, for example searching for a music clip based on artist name and song title on video platforms such as YouTube, can be achieved both based on potentially shallow human-generated metadata, or based on more profound content analysis, driven by Optical Character Recognition (OCR) or Automatic Speech Recognition (ASR). However, more advanced use cases, such as summaries or compilations of several pieces of media content covering a certain event, are hard, if not impossible to fulfill at large scale. One example of such event can be a keynote speech held at a conference, where, given a stable network connection, media content is published on social networks while the event is still going on.In our thesis, we develop a framework for media content processing, leveraging social networks, utilizing the Web of Data and fine-grained media content addressing schemes like Media Fragments URIs to provide a scalable and sophisticated solution to realize the above use cases: media content summaries and compilations. We evaluate our approach on the entity level against social media platform APIs in conjunction with Linked (Open) Data sources, comparing the current manual approaches against our semi-automated approach. Our proposed framework can be used as an extension for existing video platforms.", "", "Man Zhu", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 22:13:25", "9FS3J7SW", ""
"306", "NERD: A Framework for Evaluating Named Entity Recognition Tools in the Web of Data", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/poster-demo/35", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "In this paper, we present NERD, an evaluation framework we have developed that records and analyzes ratings of Named Entity (NE) extraction and disambiguation tools working on English plain text articles performed by human beings. NERD enables the comparison of different popular Linked Data entity extractors which expose APIs such as AlchemyAPI, DBPedia Spotlight, Extractiv, OpenCalais and Zemanta. Given an article and a particular tool, a user can assess the precision of the named entities extracted, their typing and linked data URI provided for disambiguation and their subjective relevance for the text. All user interactions are stored in a database. We propose the NERD ontology that deﬁnes mappings between the types detected by the diﬀerent NE extractors. The NERD framework enables then to visualize the comparative performance of these tools with respect to human assessment. Key words: Entity extraction, Linked Data, Natural Language Processing, Evaluation of Linked Data entity extraction tools 1", "", "Giuseppe Rizzo", "", "author", "", "Raphael Troncy", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:25:53", "8ZR7ASRT", ""
"307", "DBpedia internationalization - a graphical tool for I18n infobox-to-ontology mappings", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/poster-demo/36", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "During the past two decades, the use of the Web has spread across multiple countries and cultures. While the Semantic Web is already served in many languages, we are still facing challenges concerning its internationalization. The DBpedia project, a community eﬀort to extract structured information from Wikipedia, is already supporting multiple languages. This paper presents a graphical tool for creating internationalized mappings for DBpedia.", "", "Charalampos Bratsas", "", "author", "", "Lazaros Ioannidis", "", "author", "", "Lazaros Ioannidis", "", "author", "", "Sören Auer", "", "author", "", "Christian Bizer", "", "author", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:47:05", "VJBJBH4H", ""
"308", "TOPICA: A Tool for Visualising Emerging Semantics of POIs based on Social Awareness Streams", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/poster-demo/70", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "<i>Topica </i>is an application that enriches the Social Web with semantic data, to enable collective perception of Points of Interest (POIs), which are human constructs that describe information about locations (e.g., restaurants, attractions, cities). <i>Topica </i>provides an extra layer of information, compared to existing applications for browsing POIs, by modelling hidden characteristics of POIs, by: (1) generating a Linked Data representation of the collective perception of a POI; (2) enhancing the POI representation by mashing up services that enrich the POI’s related entities; and (3) providing a visual representation of the POIs adapted to suit userand context-sensitive ﬁlters. <i>Topica </i>identiﬁes topics relevant to a POI by extracting DBpedia categories from <i>entities </i>(e.g., People, Places) and <i>keywords</i> (e.g., Crete, Bonn) obtained from social awareness streams related to the POIs. <b>Key words: </b>Linked Data, Semantic Web, Point of Interest, Social Awareness Streams, citizen-sensing, social data mining, emerging semantics <b>1</b>", "", "A. Elizabeth Cano", "", "author", "", "Gregoire Burel", "", "author", "", "Aba-Sah Dadzie", "", "author", "", "Fabio Ciravegna", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:56:34", "BKTWQF35", ""
"309", "Effectively Interpreting Keyword Queries on RDF Databases with a Rear View", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/research/325", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "Eﬀective techniques for keyword search over RDF databases incorporate an explicit interpretation phase that maps keywords in a keyword query to structured query constructs. Because of the ambiguity of keyword queries, it is often not possible to generate a unique interpretation for a keyword query. Consequently, heuristics geared toward generating the top-K likeliest user-intended interpretations have been proposed. However, heuristics currently proposed fail to capture any userdependent characteristics, but rather depend on database-dependent properties such as occurrence frequency of subgraph pattern connecting keywords. This leads to the problem of generating top-K interpretations that are not aligned with user intentions. In this paper, we propose a contextaware approach for keyword query interpretation that personalizes the interpretation process based on a user’s query context. Our approach addresses the novel problem of using a sequence of structured queries corresponding to interpretations of keyword queries in the query history as contextual information for biasing the interpretation of a new query. Experimental results presented over DBPedia dataset show that our approach outperforms the state-of-the-art technique on both eﬃciency and eﬀectiveness, particularly for ambiguous queries.", "", "Haizhou Fu", "", "author", "", "Kemafor Anyanwu", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 22:22:44", "8VMZE2QG", ""
"311", "Leveraging Community-built Knowledge for Type Coercion in Question Answering", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/semantic-web-in-use/18", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "Watson,  the  winner  of  the  Jeopardy!  challenge,  is  a  state-of-the-art \nopen-domain Question Answering system that  tackles  the  fundamental  issue  of \nanswer typing by using a novel type coercion (TyCor) framework, where candidate answers are initially produced without considering type information, and \nsubsequent stages check whether the candidate can be coerced into the expected \nanswer type. In this paper, we provide a high-level overview of the TyCor \nframework and discuss how it is integrated in Watson, focusing on and evaluating  three  TyCor  components  that  leverage the community built semi-structured \nand structured knowledge resources -- DBpedia (in conjunction with the YAGO \nontology), Wikipedia Categories and Lists. These resources complement each \nother well in terms of precision and granularity of type information, and \nthrough links to Wikipedia, provide coverage for a large set of instances", "", "Aditya Kalyanpur", "", "author", "", "J William Murdock", "", "author", "", "James Fan", "", "author", "", "Chris Welty", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:14:32", "ETTEKCTW", ""
"312", "Zhishi.me - Weaving Chinese Linking Open Data", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/conference/iswc/2011/paper/semantic-web-in-use/70", "", "", "", "", "", "", "", "10th International Semantic Web Conference (ISWC2011)", "", "", "", "", "Linking Open Data (LOD) has become one of the most important community efforts to publish high-quality interconnected semantic data. Such data has been widely used in many applications to provide intelligent services like entity search, personalized recommendation and so on. While DBpedia, one of the LOD core data sources, contains resources described in multilingual versions and semantic data in English is proliferating, there is very few work on publishing Chinese semantic data. In this paper, we present Zhishi.me, the first effort to publish large scale Chinese semantic data and link them together as a Chinese LOD (CLOD). More precisely, we identify important structural features in three largest Chinese encyclopedia sites (i.e., Baidu Baike, Hudong Baike, and Chinese Wikipedia) for extraction and propose several data-level mapping strategies for automatic link discovery. As a result, the CLOD has more than 5 million distinct entities and we simply link CLOD with the existing LOD based on the multilingual characteristic of Wikipedia. Finally, we also introduce three Web access entries namely SPARQL endpoint, lookup interface and detailed data view, which conform to the principles of publishing data sources to LOD.", "", "Xing Niu", "", "author", "", "Xinruo Sun", "", "author", "", "Haofen Wang", "", "author", "", "Shu Rong", "", "author", "", "Guilin Qi", "", "author", "", "", "", "", "2012-05-29 21:07:48", "2012-06-02 00:12:56", "7P95GS6A", ""
"314", "Statistical Analysis of Web of Data Usage", "conferencePaper", "EvoDyn", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/workshop/evodyn/2011/paper/1", "", "", "", "", "", "", "", "Joint Workshop on Knowledge Evolution and Ontology Dynamics (EvoDyn2011)", "", "", "", "", "The Linked Data initiative gained momentum inside as well as outside of theresearch community. Thus, it is already an accepted research issue to investigate usage mining in the context ofthe Web of Data from various perspectives. We are currently working onan approach that applies such usage mining methods and analysis to support ontology and datasetmaintenance tasks. This paper presents one part of this work, namely a methodto detect errors or weaknesses within ontologies used for Linked Data populationbased on statistics and network visualizations. We contribute a detailed description of a log file preprocessing algorithm for Web of Data endpoints, a set of statistical measures that help to visualize different usage aspects, and an examplary analysis of one of the most prominent Linked Data set – DBpedia – aimed to show the feasibility and the potential of our approach.", "", "Markus Luczak-Rösch", "", "author", "", "Markus Bischo", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:51:45", "MIXP6Z27", ""
"315", "Linking Domain-Specific Knowledge to Encyclopedic Knowledge: an Initial Approach to Linked Data", "conferencePaper", "MSW", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/workshop/msw/2011/paper/3", "", "", "", "", "", "", "", "2nd Workshop on the Multilingual Semantic Web (MSW2011)", "", "", "", "", "Linked Data creates a shared information space by publishing andconnecting resources in the Semantic Web. However, the specification ofsemantic relationships between data sources is still a stumbling block. Onesolution is to enrich ontologies with multilingual and concept-orientedinformation. Usefully linking entities in the Semantic Web is thus facilitated bya semantic-oriented cross-lingual ontology mapping framework in whichknowledge representations are not restricted to a particular natural language.Accordingly, this paper describes a preliminary approach for integrating generalencyclopedic knowledge in DBpedia with EcoLexicon, a multilingualterminological knowledge base on the environment.", "", "Pilar León Araúz", "", "author", "", "Pamela Faber", "", "author", "", "Pedro J. Magaña Redondo", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:17:36", "97VVWG2K", ""
"316", "The Quad Economy of a Semantic Web Ontology Repository", "conferencePaper", "SSWS", "2011-00-00 2011", "", "", "", "http://data.semanticweb.org/workshop/ssws/2011/paper/10", "", "", "", "", "", "", "", "The 7th International Workshop on Scalable Semantic Web Knowledge Base Systems (SSWS2011)", "", "", "", "", "Publishers of Linked Data require scalable storage and retrieval in- frastructure due to the size of datasets and potentially high rate of lookups on popular sites. In this paper we investigate the feasibility of using a distributed key-value store as an underlying storage component for a Linked Data server which provides functionality for serving Linked Data via HTTP lookups and in addition offers single triple pattern lookups. We devise two storage schemes for our CumulusRDF system implemented on Apache Cassandra, an open-source key-value store. We compare the schemes with a state-of-the-art distributed RDF store on a subset of DBpedia and both synthetic workloads and workloads ob- tained from DBpedia’s access logs. Results on a cluster of up to 8 machines show that CumulusRDF is competetive to state-of-the-art distributed RDF stores.", "", "Manuel Salvadores", "", "author", "", "Paul R Alexander", "", "author", "", "Mark A. Musen", "", "author", "", "Natalya F. Noy", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:54:57", "3IEU927H", ""
"317", "Deep Answers for Naturally Asked Questions on the Web of Data", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/www/2012/demo/41", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "We present DEANNA, a framework for natural language question answering over structured knowledge bases. Given a natural language question, DEANNA translates questions into a SPARQL-like structured query language that can be evaluated over knowledge bases such as Yago, Dbpedia, Freebase, or other Linked Data sources.DEANNA analyzes questions and aims to map verbal phrases to relations and noun phrases to either individual entities or semantic classes. Importantly, it judiciously generates variables for target entities or classes to express joins between multiple triple patterns.In contrast to prior work on QA, we leverage the semantic type system for entities and we use constraints in jointly mapping the constituents of the question to relations, classes, and entities. We demonstrate the capabilities and interface of DEANNA, which allows advanced users to influence the translation process and view how the different components interact to produce the final result.", "Mohamed", "Yahya", "", "author", "Klaus", "Berberich", "", "author", "Shady", "Elbassuoni", "", "author", "Maya", "Ramanath", "", "author", "Volker", "Tresp", "", "author", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 22:14:33", "T8IEQ4QS", ""
"318", "SWiPE: Searching Wikipedia By Example", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/www/2012/demo/53", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "A novel method is demonstrated that allows semantic and well-structured knowledge bases (such as DBpedia) to be easily queried directly from Wikipedia’s pages. Using Swipe, naive users with no knowledge of RDF triples and sparql can easily query DBpedia with powerful questions such as: “Who are the U.S. presidents who took office when they were 55-year old or younger, during the last 60 years”, or “Find the town in California with less than 10 thousand people”. This is accomplished by a novel Search by Example (SBE) approach where a user can enter the query conditions directly on the Infobox of a Wikipedia page. In fact, Swipe activates various fields of Wikipedia to allow users to enter query conditions, and then uses these conditions to generate equivalent sparql queries and execute them on DBpedia. Finally, Swipe returns the query results in a form that is conducive to query refinements and further explorations. Swipe’s SBE approach makes semistructured documents queryable in an intuitive and user-friendly way and, through Wikipedia, delivers the benefits of querying and exploring large knowledge bases to all Web users.", "Maurizio", "Atzori", "", "author", "Carlo", "Zaniolo", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:52:07", "TDT5QFX2", ""
"319", "Adding Wings to Red Bull Media: Search and Display semantically enhanced Video Fragments", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/www/2012/demo/65", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "The Linked Data movement with the aims of publishing and interconnecting machine readable data has originated in the last decade. Although the set of (open) data sources is rapidly growing, the integration of multimedia in this Web of Data is still at a very early stage. This paper describes, how arbitrary video content and metadata can be processed to identify meaningful linking partners for video fragments - and thus create a web of linked media. The video test-set for our demonstrator is part of the Red Bull Content Pool and confined to the Cliff Diving domain. The candidate set of possible link targets is a combination of a Red Bull thesaurus, information about divers from www.redbull.com and concepts from DBPedia. The demo includes both a semantic search on videos and video fragments and a player for videos with semantic enhancements.", "Thomas", "Kurz", "", "author", "Sebastian", "Schaffert", "", "author", "Manuel", "Fernandez", "", "author", "Georg", "Güntner", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 20:49:58", "XTWRJKJ2", ""
"320", "Automated semantic tagging of speech audio", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/www/2012/demo/87", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "The BBC is currently tagging programmes manually, using DBpedia as a source of tag identifiers, and a list of sug- gested tags extracted from their synopsis. These tags are then used to help navigation and topic-based search of BBC programmes. However, given the very large number of pro- grammes available in the archive, most of them having very little metadata attached to them, we need a way of automat- ically assigning tags to programmes. We describe a frame- work to do so, using speech recognition, text processing and concept tagging techniques. We evaluate this framework against manually applied tags, and compare it with related work. We find that this frame- work has better performances than related work for this task, and is good enough to bootstrap the tagging process of archived content. We describe Tellytopic, an application us- ing automatically extracted tags to aid discovery of archive content.", "Yves", "Raimond", "", "author", "Chris", "Lowis", "", "author", "Jonathan", "Tweed", "", "author", "Roderick", "Hodgson", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:09:21", "ZJTXPIUR", ""
"321", "Automated Linking Data with Apache Stanbol", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/www/2012/dev/42", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "This talk will introduce the Stanbol project and showcase how it can be integrated in traditional Enterprise Content Management products.Stanbol is an Open Source project under incubation at the Apache Software Foundation. Its goal is to provide Web and CMS developers with a set of HTTP / RESTful services to help them integrate semantic technologies into their products and web sites.The following Stanbol services are currently under active developments:- Enhancement engines: use Natural Language Processing tools such as Apache OpenNLP or external services to extract knowledge (topics, named entities, facts) from unstructured content and link it to unambiguous URIs from reference knowledge bases;- Entity Hub: a Linked Data indexing cache built on top of Apache Solr, Clerezza and Jena that comes with precomputed indexes and live connectors to popular knowledge bases such as DBpedia, Geonames, YAGO or custom SKOS taxonomies...- Content Hub: a faceted search engine based on Solr to search for content using the knowledge automatically extracted by the enhancement engines;- CMS bridges to lift the structured content of document repositories using the JCR and CMIS access protocols (using Apache Chemistry) and store the result into a triple store suitable for SPARQL access;- Rules engine based on Apache Jena for knowledge refactoring (e.g. convert extracted knowledge into the rich snippet vocabulary for SEO), integrity checks, merging rules, deductive inference...The Semantic Web has made significant progress over the last years, and while it always gave a lot of promises, it is now the time where it can concretely be used in Enterprise Solutions.If you are curious about the web of data, and want to see how concretely it can be used and integrated today in enterprise solutions thanks to software like the Stanbol projects, this session is for you.Stanbol project homepage: https://incubator.apache.org/stanbol/Full stanbol demo of Stanbol Services: http://dev.iks-project.eu:8081/## Note for the reviewers (to be removed from the published abstract):Here is the slide deck of a similar talk I gave a ApacheCon in November 2011. http://www.slideshare.net/nuxeo/apache-stanbol-and-the-web-of-data-apachecon-2011You can also connect to this Nuxeo Document Management demo that uses Stanbol:http://temis.demo.nuxeo.comLogin: AdministratorPassword: AdministratorTo test the Nuxeo / Stanbol / Temis / DBpedia integration you can go to a workspace an create a new document of type ""Note"" and copy and paste text from some wikinews article. Upon saving the content will automatically get analyzed and linked to referenced entities.Note: this demo has not been updated for a while. For wwww2012 I will also be able to demonstrate automated topic classification (rather that just entities occurences).", "Olivier", "Grisel", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:08:56", "8ZZHTVEH", ""
"322", "Compressed Data Structures for Annotated Web Search", "conferencePaper", "WWW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/www/2012/paper/773", "", "", "", "", "", "", "", "21st International World Wide Web Conference (WWW2012)", "", "", "", "", "Entity relationship search at Web scale depends on adding dozens of entity annotations to each of billions of crawled pages and indexing the annotations at rates comparable to regular text indexing. Even small entity search benchmarks from TREC and INEX suggest that the entity catalog support thousands of entity types and tens to hundreds of millions of entities. The above targets raise many challenges, major ones being the design of highly compressed data structures in RAM for spotting and disambiguating entity mentions, and highly compressed disk-based annotation indices. These data structures cannot be readily built upon standard inverted indices. Here we present the fastest known Web scale entity annotator. Using a new workload-sensitive compressed multilevel map, we fit statistical disambiguation models for millions of entities within 1.1GB of RAM, and spend about 0.6 core-milliseconds per disambiguation. In contrast, DBPedia Spotlight spends 158 milliseconds, Wikipedia Miner spends 21 milliseconds, and Zemanta spends 9.5 milliseconds. Our annotation indices use ideas from vertical databases to reduce storage by 30%. On 40x8 cores with 40x3 disk spindles, we can annotate and index a billion Web pages with Wikipedia's two million entities and over 200,000 types in about a day. Index decompression and scan speed is comparable to MG4J.", "Sasidhar", "Kasturi", "", "author", "Soumen", "Chakrabarti", "", "author", "Ganesh", "Ramakrishnan", "", "author", "Bharath", "Balakrishnan", "", "author", "Rohit", "Saraf", "", "author", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:22:26", "KQPTC7TM", ""
"323", "Automated interlinking of speech radio archives", "conferencePaper", "LDOW", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/workshop/ldow/2012/paper/15", "", "", "", "", "", "", "", "LDOW 2012 : linked Data on the web (LDOW2012)", "", "", "", "", "The BBC is currently tagging programmes manually, using DBpedia as a source of tag identifiers, and a list of suggested tags extracted from their synopsis. These tags are then used to help navigation and topic-based search of BBC programmes. However, given the very large number of programmes available in the archive, most of them having very little metadata attached to them, we need a way of automatically assigning tags to programmes. We describe a framework to do so, using speech recognition, text processing and concept tagging techniques. We evaluate this framework against manually applied tags, and compare it with related work. We find that this framework is good enough to bootstrap the interlinking process of archived content.", "Yves", "Raimond", "", "author", "Chris", "Lowis", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 21:08:42", "QRBWJMRC", ""
"324", "Synchronizing semantic stores with Commutative Replicated Data Types", "conferencePaper", "SWCS", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/workshop/swcs/2012/paper/13", "", "", "", "", "", "", "", "SWCS: Semantic Web Collaborative Spaces (SWCS 2012)", "", "", "", "", "Social semantic web technologies led to huge amounts of data and information being available. The production of knowledge from this information is challenging, and ma- jor efforts, like DBpedia, has been done to make it reality. Linked data provides interconnection between this informa- tion, extending the scope of the knowledge production. The knowledge construction between decentralized sources in the web follows a co-evolution scheme, where knowledge’s generated collaboratively and continuously. Sources are also autonomous, meaning that they can use and publish only the information they want. The updating of sources with this criteria is intimately re- lated with the problem of synchronization, and the consis- tency between all the replicas managed. Recently, a new family of algorithms called Commutative Replicated Data Types have emerged for ensuring eventual consistency in highly dynamic environments. In this paper, we define SU-Set, a CRDT for RDF-Graph that supports SPARQL Update 1.1 operations.", "Luis Daniel", "Ibáñez", "", "author", "Hala", "Skaf-Molli", "", "author", "Pascal", "Molli", "", "author", "Olivier", "Corby", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:52:13", "QF8398AX", ""
"325", "Nobody Wants to Live in a Cold City where no Music Has Been Recorded - Analyzing Statistics with Explain-a-LOD", "conferencePaper", "ESWC", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/eswc/2012/paper/demonstation/315", "", "", "", "", "", "", "", "9th Extended Semantic Web Conference (ESWC2012)", "", "", "", "", "While it is easy to find statistics on almost every topics, coming up with an explanation about those statistics is a much more difficult task. This demo showcases the prototype tool Explain-a-LOD, which uses background knowledge from DBpedia for generating possible explanations for a statistic.", "Heiko", "Paulheim", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:26:09", "78UFEJMX", ""
"326", "Exploiting Information Extraction, Reasoning and Machine Learning for Relation Prediction", "conferencePaper", "ESWC", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/eswc/2012/paper/research/171", "", "", "", "", "", "", "", "9th Extended Semantic Web Conference (ESWC2012)", "", "", "", "", "The three most common approaches for deriving or predicting instantiated relations, i.e. triple statements (s, p, o), are information extraction, reasoning and relational machine learning. Information extraction uses sensory information, typically in form of text, and extracts statements using various methods ranging from simple classifiers to the most sophisticated NLP approaches. Logical reasoning is based on a set of true statements and derives new statements via inference using higher-order logical axioms. Finally, machine learning exploits regularities in the data to predict the likelihood of new statements. In this paper we combine all three methods to exploit all sources of available information in a modular way, by which we mean that each approach, i.e., information extraction, reasoning, machine learning, can be optimized independently to be combined in an overall system. For relational machine learning, we present a novel approach based on hierarchical Bayesian multi-label learning which also sheds new light on common factorization approaches. We rank the probabilities for statements to be true in the sense that: given that we are forced to make a decision, what is the best option. We consider the fact that an entity can belong to more than one ontological class and discuss aggregation. We extend the approach to modeling nonlinear dependencies between relationships and for personalization. We validate our model using data from the Yago and the DBpedia ontology.", "Xueyan", "Jiang", "", "author", "Yi", "Huang", "", "author", "Maximilian", "Nickel", "", "author", "Volker", "Tresp", "", "author", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 22:29:29", "2KGPXUI8", ""
"327", "LODifier: Generating Linked Data from Unstructured Text", "conferencePaper", "ESWC", "2012-00-00 2012", "", "", "", "http://data.semanticweb.org/conference/eswc/2012/paper/research/73", "", "", "", "", "", "", "", "9th Extended Semantic Web Conference (ESWC2012)", "", "", "", "", "The automated extraction of information from text and its transformation into a formal description is an important goal of in both Semantic Web research and computational linguistics. The extracted information can be used for a variety of tasks such as ontology generation, question answering and information retrieval. LODifier is an approach that combines deep semantic analysis with named entity recognition, word-sense disambiguation and controlled Semantic Web vocabularies in order to extract named entities and relations between them from text and to convert them into an RDF representation which is linked to DBpedia and WordNet. We present the architecture of our tool and discuss design decisions made. Evaluations of the tool give clear evidence of its potential for tasks like information extraction and computing document similarity.", "Isabelle", "Augenstein", "", "author", "Sebastian", "Pado", "", "author", "Sebastian", "Rudolph", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-29 21:07:48", "2012-06-01 23:18:06", "KDB3RDZZ", ""
"328", "DBpedia Live Extraction", "conferencePaper", "OTM", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "On the Move to Meaningful Internet Systems: OTM 2009", "", "", "", "", "", "Sebastian", "Hellmann", "", "author", "Claus", "Stadler", "", "author", "Jens", "Lehmann", "", "author", "Sören", "Auer", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 21:53:39", "QI2TN9MI", ""
"329", "DBpedia - A crystallization point for the Web of Data.", "journalArticle", "", "2009-00-00 2009", "", "", "", "", "J. Web Sem.", "", "", "", "", "", "", "", "", "", "", "", "", "Christian", "Bizer", "", "author", "Jens", "Lehmann", "", "author", "Georgi", "Kobilarov", "", "author", "Sören", "Auer", "", "author", "Christian", "Becker", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 21:23:35", "SIWT6CCU", ""
"331", "DBpedia: A Nucleus for a Web of Open Data.", "conferencePaper", "ISWC/ASWC", "2007-00-00 2007", "", "", "", "", "", "", "", "", "", "", "", "In Proceedings of 6th International Semantic Web Conference, 2nd Asian Semantic Web Conference (ISWC+ASWC 2007)", "", "", "", "", "", "Sören", "Auer", "", "author", "Christian", "Bizer", "", "author", "Georgi", "Kobilarov", "", "author", "Jens", "Lehmann", "", "author", "Richard", "Cyganiak", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 21:34:36", "EZKTMIZ6", ""
"333", "Multipedia: enriching DBpedia with multimedia information.", "conferencePaper", "K-CAP", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "K-CAP", "", "", "", "", "", "Andrés", "García-Silva", "", "author", "Max", "Jakob", "", "author", "Pablo N.", "Mendes", "", "author", "Christian", "Bizer", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-21 18:18:37", "87K38W57", ""
"334", "Modelling provenance of DBpedia resources using Wikipedia contributions.", "journalArticle", "", "2011-00-00 2011", "", "", "", "", "J. Web Sem.", "", "", "", "", "", "", "", "", "", "", "", "", "Fabrizio", "Orlandi", "", "author", "Alexandre", "Passant", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-05-31 16:11:08", "U4TKRFCP", ""
"337", "Ranking the Linked Data: The Case of DBpedia.", "conferencePaper", "ICWE", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "ICWE", "", "", "", "", "", "Roberto", "Mirizzi", "", "author", "Azzurra", "Ragone", "", "author", "Tommaso Di", "Noia", "", "author", "Eugenio Di", "Sciascio", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:29:51", "PJ8KKQBH", ""
"338", "dbrec - Music Recommendations Using DBpedia", "conferencePaper", "ISWC", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "9th International Semantic Web Conference (ISWC2010)", "", "", "", "", "This paper describes the theoretical background and the implementation of dbrec, a music recommendation system built on top of DBpedia, offering recommendations for more than 39,000 bands and solo artists. We discuss the various challenges and lessons learnt while building it, providing relevant insights for people developing applications consuming Linked Data. Furthermore, we provide a user-centric evaluation of the system, notably by comparing it to last.fm.", "Alexandre", "Passant", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:12:19", "MRSJKIRU", ""
"340", "Mapping queries to the Linking Open Data cloud: A case study using DBpedia.", "journalArticle", "", "2011-00-00 2011", "", "", "", "", "J. Web Sem.", "", "", "", "", "", "", "", "", "", "", "", "", "Edgar", "Meij", "", "author", "Marc", "Bron", "", "author", "Laura", "Hollink", "", "author", "Bouke", "Huurnink", "", "author", "Maarten de", "Rijke", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-05-31 16:11:08", "WPHD2NQF", ""
"344", "Media Meets Semantic Web - How the BBC Uses DBpedia and Linked Data to Make Connections.", "conferencePaper", "ESWC", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "ESWC", "", "", "", "", "", "Georgi", "Kobilarov", "", "author", "Tom", "Scott", "", "author", "Yves", "Raimond", "", "author", "Silver", "Oliver", "", "author", "Chris", "Sizemore", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:19:38", "KWJQITFU", ""
"345", "Discovering Unknown Connections - the DBpedia Relationship Finder.", "conferencePaper", "CSSW", "2007-00-00 2007", "", "", "", "", "", "", "", "", "", "", "", "CSSW", "", "", "", "", "", "Jens", "Lehmann", "", "author", "Jörg", "Schüppel", "", "author", "Sören", "Auer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:16:13", "KPZBIQNQ", ""
"347", "Clustering of Rough Set Related Documents with Use of Knowledge from DBpedia.", "conferencePaper", "RSKT", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the 6th international conference on Rough sets and knowledge technology", "", "", "", "", "", "Marcin S.", "Szczuka", "", "author", "Andrzej", "Janusz", "", "author", "Kamil", "Herba", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 21:21:53", "CZEPW2SA", ""
"348", "A Framework for Visualizing the Web of Data: Combining DBpedia and Open APIs.", "conferencePaper", "PCI", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "Panhellenic Conference on Informatics", "", "", "", "", "", "Agis", "Papantoniou", "", "author", "Vassilis", "Loumos", "", "author", "Miltos", "Poulizos", "", "author", "Gregory", "Rigas", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 21:03:55", "F3XNTQ6X", ""
"352", "Implementing an Image Search System with Integrating Social Tags and DBpedia.", "conferencePaper", "KES", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "Knowledge-Based and Intelligent Information and Engineering Systems", "", "", "", "", "", "Chie", "Iijima", "", "author", "Makito", "Kimura", "", "author", "Takahira", "Yamaguchi", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:45:32", "K3NREBSX", ""
"353", "DBpedia SPARQL Benchmark - Performance Assessment with Real Queries on Real Data.", "conferencePaper", "ISWC", "2011-00-00 2011", "", "", "", "", "", "", "", "", "", "", "", "International Semantic Web Conference (1)", "", "", "", "", "", "Mohamed", "Morsey", "", "author", "Jens", "Lehmann", "", "author", "Sören", "Auer", "", "author", "Axel-Cyrille Ngonga", "Ngomo", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:08:50", "NEIJAIUF", ""
"356", "From information to knowledge: harvesting entities and relationships from web sources.", "conferencePaper", "PODS", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "PODS", "", "", "", "", "", "Gerhard", "Weikum", "", "author", "Martin", "Theobald", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:33:37", "XW5TTJTT", ""
"357", "Vispedia: on-demand data integration for interactive visualization and exploration.", "conferencePaper", "SIGMOD", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "SIGMOD Conference", "", "", "", "", "", "Bryan", "Chan", "", "author", "Justin", "Talbot", "", "author", "Leslie", "Wu", "", "author", "Nathan", "Sakunkoo", "", "author", "Mike", "Cammarano", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-21 18:19:15", "HG3MT57E", ""
"358", "SemaPlorer - Interactive semantic exploration of data and media based on a federated cloud infrastructure.", "journalArticle", "", "2009-00-00 2009", "", "", "", "", "J. Web Sem.", "", "", "", "", "", "", "", "", "", "", "", "", "Simon", "Schenk", "", "author", "Carsten", "Saathoff", "", "author", "Steffen", "Staab", "", "author", "Ansgar", "Scherp", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-05-31 16:11:08", "VMSNASQZ", ""
"359", "Revyu: Linking reviews and ratings into the Web of Data.", "journalArticle", "", "2008-00-00 2008", "", "", "", "", "J. Web Sem.", "", "", "", "", "", "", "", "", "", "", "", "", "Tom", "Heath", "", "author", "Enrico", "Motta", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-05-31 16:11:08", "EBQBQNNI", ""
"360", "Extracting Enterprise Vocabularies Using Linked Open Data.", "conferencePaper", "ISWC", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "8th International Semantic Web Conference (ISWC2009)", "", "", "", "", "A common vocabulary is vital to smooth business operation, yet codifying and maintaining an enterprise vocabulary is an arduous, manual task. We describe a process to automatically extract a domain specific vocabulary (terms and types) from unstructured data in the enterprise guided by term definitions in Linked Open Data (LOD). We validate our techniques by applying them to the IT (Information Technology) domain, taking 58 Gartner analyst reports and using two specific LOD sources – DBpedia and Freebase.", "Julian", "Dolby", "", "author", "Achille", "Fokoue", "", "author", "Aditya", "Kalyanpur", "", "author", "Edith", "Schonberg", "", "author", "Kavitha", "Srinivas", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:31:12", "3RCVTTIV", ""
"361", "Learning Semantic Query Suggestions", "conferencePaper", "ISWC", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "8th International Semantic Web Conference (ISWC2009)", "", "", "", "", "An important application of semantic web technology is recognizing human-defined concepts in text. Query transformation is a strategy often used in search engines to derive queries that are able to return more useful search results than the original query and most popular search engines provide facilities that let users complete, specify, or reformulate their queries. We study the problem of semantic query suggestion, a special type of query transformation based on identifying semantic concepts contained in user queries. We use a feature-based approach in conjunction with supervised machine learning, augmenting term-based features with search history-based and concept-specific features. We apply our method to the task of linking queries from real-world query logs (the transaction logs of the Netherlands Institute for Sound and Vision) to the DBpedia knowledge base. We evaluate the utility of different machine learning algorithms, features, and feature types in identifying semantic concepts using a manually developed test bed and show significant improvements over an already high baseline. The resources developed for this paper, i.e., queries, human assessments, and extracted features, are available for download.", "Edgar", "Meij", "", "author", "Marc", "Bron", "", "author", "Laura", "Hollink", "", "author", "Bouke", "Huurnink", "", "author", "Maarten de", "Rijke", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:11:18", "KISHW9RI", ""
"364", "Enrichment and Ranking of the YouTube Tag Space and Integration with the Linked Data Cloud.", "conferencePaper", "ISWC", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "8th International Semantic Web Conference (ISWC2009)", "", "", "", "", "The increase of personal digital cameras with video functionality and video-enabled camera phones has increased the amount of user-generated videos on the Web. People are spending more and more time viewing online videos as a major source of entertainment and infotainment. Social websites allow users to assign shared free-form tags to user-generated multimedia resources, thus generating annotations for objects with a minimum amount of effort. Tagging allows communities to organize their multimedia items into browseable sets, but these tags may be poorly chosen and related tags may be omitted. Current techniques to retrieve, integrate and present this media to users are deficient and could do with improvement. In this paper we describe a framework for semantic enrichment, ranking and integration of web video tags using Semantic Web technologies. Semantic enrichment of folksonomies can bridge the gap between the uncontrolled and flat structures typically found in user-generated content and structures provided by the Semantic Web. The enhancement of tag spaces with semantics has been accomplished through two major tasks: (1) a tag space expansion and ranking step; and (2) through concept matching and integration with the Linked Data cloud. We have explored social, temporal and spatial contexts to enrich and extend the existing tag space. The resulting semantic tag space is modelled via a local graph based on co-occurrence distances for ranking. A ranked tag list is mapped and integrated with the Linked Data cloud through the DBpedia resource repository. Multi-dimensional context filtering for tag expansion means that tag ranking is much easier and it provides less ambiguous tag to concept matching.", "Smitashree", "Choudhury", "", "author", "John G.", "Breslin", "", "author", "Alexandre", "Passant", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:25:11", "SAU57UW7", ""
"365", "Refining non-taxonomic relation labels with external structured data to support ontology learning.", "journalArticle", "", "2010-00-00 2010", "", "", "", "", "Data Knowl. Eng.", "", "", "", "", "", "", "", "", "", "", "", "This paper presents a method to integrate external knowledge sources such as DBpedia and OpenCyc into an ontologylearning system that automatically suggests labels for unknown relations in domain ontologies based on large corpora of unstructured text. The method extracts and aggregates verb vectors from semantic relations identified in the corpus. It composes a knowledge base which consists of (i) verb centroids for known relations between domain concepts, (ii) mappings between concept pairs and the types of known relations, and (iii) ontological knowledge retrieved from external sources. Applying semantic inference and validation to this knowledge base improves the quality of suggested relationlabels. A formal evaluation compares the accuracy and average ranking precision of this hybrid method with the performance of methods that solely rely on corpus data and those that are only based on reasoning and externaldata sources.", "Albert", "Weichselbraun", "", "author", "Gerhard", "Wohlgenannt", "", "author", "Arno", "Scharl", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:36:42", "EMZJQAWI", ""
"366", "Dynamic linking and personalization on web.", "conferencePaper", "SAC", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the 2010 ACM Symposium on Applied Computing", "", "", "", "", "Web browsing is a complex activity and users need to be supported with additional guidance. In our research, we developed a novel Semantic Web browser, which is called SemWeB, in order to assist Web browsing using linked data and Adaptive Hypermedia (AH). SemWeB is an extension to the Mozilla Firefox Web browser. SemWeB adds a semantic layer to Web documents: it annotates Web pages using a linked data domain (i.e. DBpedia) and creates context-based hyperlinks on Web pages to guide users to relevant pages. In addition, the information presented to the user is personalized based on a novel behavior based user model. We evaluated our approach on DBpedia, DBLP and ECS (University of Southampton) linked data domains. Our study showed that SemWeB provides a new way of supporting dynamic linking and personalization on Web documents using different linked data domains.", "Melike", "Sah", "", "author", "Wendy", "Hall", "", "author", "David De", "Roure", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:21:33", "VTR7JBZD", ""
"367", "Integrating Structural Data into Methods for Labeling Relations in Domain Ontologies.", "conferencePaper", "DEXA", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "20th International Conference on Database and Expert Systems Application", "", "", "", "", "", "Gerhard", "Wohlgenannt", "", "author", "Albert", "Weichselbraun", "", "author", "Arno", "Scharl", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:07:04", "ZTHN3TQA", ""
"368", "Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration.", "journalArticle", "", "2008-00-00 2008", "", "", "", "", "IEEE Trans. Vis. Comput. Graph.", "", "", "", "", "", "", "", "", "", "", "", "", "Bryan", "Chan", "", "author", "Leslie", "Wu", "", "author", "Justin", "Talbot", "", "author", "Mike", "Cammarano", "", "author", "Pat", "Hanrahan", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-05-31 16:11:08", "WSKAEIMK", ""
"369", "Efficient Indices Using Graph Partitioning in RDF Triple Stores.", "conferencePaper", "ICDE", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "ICDE", "", "", "", "", "With the advance of the semantic Web, varying RDF data were increasingly generated, published, queried, and reused via the Web. For example, the DBpedia, a community effort to extract structured data from Wikipedia articles, broke 100 million RDF triples in its latest release. Initiated by Tim Berners-Lee,likewise, the Linking Open Data (LOD) project has published and interlinked many open licence datasets which consisted of over 2 billion RDF triples so far. In this context, fast query response over such large scaled data would be one of the challenges to existing RDF data stores. In this paper, we propose a novel triple indexing scheme to help RDF query engine fast locate the instances within a small scope. By considering the RDF data as a graph, we would partition the graph into multiple subgraph pieces and store them individually, over which a signature tree would be built up to index the URIs. When a query arrives, the signature tree index is used to fast locate the partitions that might include the matches of the query by its constant URIs. Our experiments indicate that the indexing scheme dramatically reduces the query processing time in most cases because many partitions would be early filtered out and the expensive exact matching is only performed over a quite small scope against the original dataset.", "Ying", "Yan", "", "author", "Chen", "Wang", "", "author", "Aoying", "Zhou", "", "author", "Weining", "Qian", "", "author", "Li", "Ma", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:24:25", "6TJ79IWZ", ""
"370", "Language-model-based ranking for queries on RDF-graphs.", "conferencePaper", "CIKM", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "CIKM", "", "", "", "", "", "Shady", "Elbassuoni", "", "author", "Maya", "Ramanath", "", "author", "Ralf", "Schenkel", "", "author", "Marcin", "Sydow", "", "author", "Gerhard", "Weikum", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:09:30", "4C9N6GG6", ""
"371", "RelFinder: Revealing Relationships in RDF Knowledge Bases.", "conferencePaper", "SAMT", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "SAMT", "", "", "", "", "", "Philipp", "Heim", "", "author", "Sebastian", "Hellmann", "", "author", "Jens", "Lehmann", "", "author", "Steffen", "Lohmann", "", "author", "Timo", "Stegemann", "", "author", "", "", "", "", "2012-05-31 16:11:08", "2012-06-21 18:20:20", "THXQVQ4I", ""
"372", "Gathering and ranking photos of named entities with high precision, high recall, and diversity.", "conferencePaper", "WSDM", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "WSDM", "", "", "", "", "", "Bilyana", "Taneva", "", "author", "Mouna", "Kacimi", "", "author", "Gerhard", "Weikum", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:35:11", "9RHPRBT5", ""
"373", "Exploiting external knowledge to improve video retrieval.", "conferencePaper", "MIR", "2010-00-00 2010", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the international conference on Multimedia information retrieval", "", "", "", "", "Most video retrieval systems are multimodal, commonly relying on textual information, low- and high-level semantic features extracted from query visual examples. In this work, we study the impact of exploiting different knowledge sources in order to automatically retrieve query visual examples relevant to a video retrieval task. Our hypothesis is that the exploitation of external knowledge sources can help on the identification of query semantics as well as on improving the understanding of video contents.\n\nWe propose a set of techniques to automatically obtain additional query visual examples from different external knowledge sources, such as DBPedia, Flickr and Google Images, which have different coverage and structure characteristics. The proposed strategies attempt to exploit the semantics underlying the above knowledge sources to reduce the ambiguity of the query, and to focus the scope of the image searches in the repositories.\n\nWe assess and compare the quality of the images obtained from the different external knowledge sources when used as input of a number of video retrieval tasks. We also study how much they complement manually provided sets of examples, such as those given by TRECVid tasks.\n\nBased on our experimental results, we report which external knowledge source is more likely to be suitable for the evaluated retrieval tasks. Results also demonstrate that the use of external knowledge can be a good complement to manually provided examples and, when lacking of visual examples provided by a user, our proposed approaches can retrieve visual examples to improve the user's query.", "David", "Vallet", "", "author", "Iván", "Cantador", "", "author", "Joemon M.", "Jose", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:28:38", "8ZFBV97S", ""
"374", "Learning to Tag and Tagging to Learn: A Case Study on Wikipedia.", "journalArticle", "", "2008-00-00 2008", "", "", "", "", "IEEE Intelligent Systems", "", "", "", "", "", "", "", "", "", "", "", "", "Peter", "Mika", "", "author", "Massimiliano", "Ciaramita", "", "author", "Hugo", "Zaragoza", "", "author", "Jordi", "Atserias", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-05-31 16:11:08", "AWFI2MCK", ""
"375", "CE2: towards a large scale hybrid search engine with integrated ranking support.", "conferencePaper", "CIKM", "2008-00-00 2008", "", "", "", "", "", "", "", "", "", "", "", "Proceedings of the 17th Conference on Information and Knowledge Management (CIKM'08)", "", "", "", "", "", "Haofen", "Wang", "", "author", "Thanh", "Tran", "", "author", "Chang", "Liu", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 21:15:52", "SP2WP5R4", ""
"376", "RDF Data-Centric Storage", "conferencePaper", "ICWS", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "ICWS", "", "", "", "", "", "Justin J.", "Levandoski", "", "author", "Mohamed F.", "Mokbel", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:30:17", "N9NE98S2", ""
"377", "Integrating Open Sources and Relational Data with SPARQL.", "conferencePaper", "ESWC", "2008-00-00 2008", "", "", "", "", "", "", "", "", "", "", "", "ESWC", "", "", "", "", "", "Orri", "Erling", "", "author", "Ivan", "Mikhailov", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 23:06:05", "3WJDU87K", ""
"379", "Harvesting, searching, and ranking knowledge on the web: invited talk.", "conferencePaper", "WSDM", "2009-00-00 2009", "", "", "", "", "", "", "", "", "", "", "", "WSDM", "", "", "", "", "", "Gerhard", "Weikum", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-01 22:41:05", "XRKXNDTB", ""
"380", "Revyu.com: A Reviewing and Rating Site for the Web of Data.", "conferencePaper", "ISWC/ASWC", "2007-00-00 2007", "", "", "", "", "", "", "", "", "", "", "", "ISWC/ASWC", "", "", "", "", "", "Tom", "Heath", "", "author", "Enrico", "Motta", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-21 18:21:02", "VT3CFDSA", ""
"381", "Utilizing Federated Knowledge in Semantic Web Applications.", "conferencePaper", "ICSC", "2008-00-00 2008", "", "", "", "", "", "", "", "", "", "", "", "ICSC", "", "", "", "", "", "Jans", "Aasman", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 16:11:08", "2012-06-02 00:08:18", "I28EG4I2", ""
"382", "A Scalable Approach for Statistical Learning in Semantic Graphs", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "SWJ", "", "", "", "", "", "", "", "", "", "", "", "Increasingly, data is published in form of semantic graphs. The most notable example is the Linked Open Data (LOD) initiative where an increasing number of data sources are published in the Semantic Web’s Ressource Description Framework and where the various data sources are linked to reference one another. In this paper we apply machine learning to semantic graph data and argue that scalability and robustness can be achieved via an urn-based statistical sampling scheme. We apply the urn model to the SUNS framework which is based on multivariate prediction. We argue that multivariate prediction approaches are most suitable for dealing with the resulting high-dimensional sparse data matrix. Within the statistical framework, the approach scales up to large domains and is able to deal with highly sparse relationship data. We summarize experimental results using a friend-of-a-friend data set and a data set derived from DBpedia. In more detail, we describe novel experiments on disease gene prioritization using LOD data sources. The experiments confirm the ease-of-use, the scalability and the good performance of the approach.", "", "Yi Huang", "", "author", "", "Volker Tresp", "", "author", "", "Maximilian Nickel", "", "author", "", "Achim Rettinger", "", "author", "", "Hans-Peter Kriegel", "", "author", "", "", "", "", "2012-05-31 17:03:55", "2012-05-31 17:06:25", "5B6UCB8U", ""
"383", "Amsterdam Museum Linked Open Data", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "SWJ", "", "", "", "", "", "", "", "", "", "", "", "In this document we describe the Amsterdam Museum Linked Open Data set. The dataset is a five-star Linked Data representation and comprises the entire collection of the Amsterdam Museum consisting of more than 70.000 object descriptions. Furthermore, the institution’s thesaurus and person authority files used in the object metadata are included in the Linked Data set. The data is mapped to the Europeana Data Model, utilizing Dublin Core, SKOS, RDA-group2 elements and the OAI-ORE model to represent the museum data. Vocabulary concepts are mapped to Geonames and DBpedia. The two main contributions of this dataset are the inclusion of internal vocabularies and the fact that the complexity of the original dataset is retained.", "", "Victor de Boer", "", "author", "", "Jan Wielemaker", "", "author", "", "Judith van Gent", "", "author", "", "Marijke Oosterbroek", "", "author", "", "Michiel Hildebrand", "", "author", "", "", "", "", "2012-05-31 17:07:40", "2012-05-31 17:09:48", "W64DIIQF", ""
"384", "IDSWrapper: a Linked Data interface to the Institute for Development Studies’ data", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "SWJ", "", "", "", "", "", "", "", "", "", "", "", "This short paper provides a description of the IDS Wrapper used to expose the data from the Institute for Development Studies’ Knowledge Services as Linked Open Data. The IDS Wrapper provides Linked Data access to 35,000 research documents on development research as well as its medata. The IDS Wrapper links this metadata to a number of external sources: DBpedia, GeoNames, Lexvo and the IATI Linked Data set. We expect that the IDS data will play a central role in the larger web of Linked Data for global development.", "", "Christophe Guéret", "", "author", "", "Victor de Boer", "", "author", "", "Duncan Edwards", "", "author", "", "Timothy G. Davies", "", "author", "", "", "", "", "", "", "", "", "2012-05-31 17:09:58", "2012-05-31 17:11:01", "MTBDCIX4", ""
"385", "Europeana Linked Open Data – data.europeana.eu", "journalArticle", "", "2012-00-00 2012", "", "", "", "", "SWJ", "", "", "", "", "", "", "", "", "", "", "", "Europeana is a single access point to millions of books, paintings, films, museum objects and archival records that have been digitized throughout Europe. The data.europeana.eu Linked Open Data pilot dataset contains open metadata on approximately 2.4 million texts, images, videos and sounds gathered by Europeana. All metadata are released under Creative Commons CC0 and therefore dedicated to the public domain. The metadata follow the Europeana Data Model and clients can access data either by dereferencing URIs, downloading data dumps, or executing SPARQL queries against the dataset. They can also follow the links to external linked data sources, such as the Swedish cultural heritage aggregator (SOCH), GeoNames, the GEMET thesaurus, or DBPedia. The latest dataset release has been published in February 2012.", "", "Antoine Isaac", "", "author", "", "Bernhard Haslhofer", "", "author", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "2012-05-31 17:11:39", "2012-05-31 17:12:24", "JQQN4CDZ", ""
